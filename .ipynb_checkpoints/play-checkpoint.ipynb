{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path: str, content: str) -> None:\n",
    "    # if dir doesn't exist, create dir\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    file = open(path, \"w\")\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44972/44972 [00:00<00:00, 2058429.43it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./baike_qa_valid.json\", \"r\") as file:\n",
    "    res = [\"[\\n\"]\n",
    "    for line in tqdm(file.readlines()):\n",
    "        content = line[:-1] + \",\\n\"\n",
    "        res.append(content)\n",
    "    res[-1] = res[-1][:-2] + \"\\n\"\n",
    "    res.append(\"]\")\n",
    "    save(\"./baike.json\", \"\".join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token 化字符串\n",
    "\n",
    "使用 `BertTokenizer` 的预训练模型 `bert-base-chinese` 将字符串转换为 token 序列。\n",
    "\n",
    "首先安装这个与训练模型\n",
    "\n",
    "```shell\n",
    "git clone https://huggingface.co/bert-base-chinese\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 2230, 5500,  677, 7270,  749,  702, 4582, 8024, 3221,  784,  720,\n",
      "         4567, 8043,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "example_text = '屁股上长了个痣，是什么病？'\n",
    "\n",
    "bert_input: torch.Tensor = tokenizer(example_text, padding=\"max_length\", max_length=24, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(bert_input[\"input_ids\"])\n",
    "print(bert_input[\"token_type_ids\"])\n",
    "print(bert_input[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_ids` 代表了句子中每个词的 token。\n",
    "\n",
    "- `token_type_ids` ，它是一个二进制掩码，用于标识令牌所属的序列。如果我们只有一个序列，那么所有的 token 类型 id 都将为 0。对于文本分类任务，token_type_ids 是我们 BERT 模型的可选输入。\n",
    "\n",
    "- `attention_mask` ，它是一个二进制掩码，用于标识标记是真实单词还是只是填充。如果 token 包含 [CLS]、[SEP] 或任何真实单词，则掩码将为 1。同时，如果令牌只是填充或 [PAD]，则掩码将为 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 屁 股 上 长 了 个 痣 ， 是 什 么 病 ？ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(bert_input[\"input_ids\"][0])  # 解码成原文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读数据\n",
    "dataset = pd.read_json(\"./baike.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "游戏-网络游戏           3086\n",
       "娱乐-博彩             1576\n",
       "烦恼-恋爱             1279\n",
       "电脑/网络-互联网-上网帮助    1277\n",
       "商业/理财-股票          1268\n",
       "                  ... \n",
       "电脑/网络-百度-百度知道        1\n",
       "医疗健康-五官科-耳鼻喉科        1\n",
       "医疗健康-妇产科-产科          1\n",
       "游戏-腾讯游戏-英雄联盟         1\n",
       "娱乐休闲-收藏              1\n",
       "Name: category, Length: 321, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qid_1815059893214501395</td>\n",
       "      <td>烦恼</td>\n",
       "      <td>请问深入骨髓地喜欢一个人怎么办我不能确定对方是不是喜欢我，我却想</td>\n",
       "      <td>我不能确定对方是不是喜欢我，我却想分分秒秒跟他在一起，有谁能告诉我如何能想他少一点</td>\n",
       "      <td>一定要告诉他你很喜欢他 很爱他!!  虽然不知道你和他现在的关系是什么！但如果真的觉得很喜欢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qid_2063849676113062517</td>\n",
       "      <td>游戏</td>\n",
       "      <td>我登陆诛仙2时总说我账号密码错误，但是我打的是正确的，就算不对我?</td>\n",
       "      <td></td>\n",
       "      <td>被盗号了~我的号在22号那天被盗了，跟你一样情况，link密码与账号错误，我密保都有了呐，邮...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qid_6625582808814915192</td>\n",
       "      <td>游戏</td>\n",
       "      <td>斩魔仙者称号怎么得来的</td>\n",
       "      <td>斩魔仙者称号怎么得来的</td>\n",
       "      <td>楼主您好，以下为转载：\\r\\r圣诞前热身 来《生肖传说》做斩魔仙者\\r\\r　　一年一度的圣诞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qid_9204493405205415849</td>\n",
       "      <td>商业</td>\n",
       "      <td>有哪位好心人上传一份女衬衫的加拿大海关发票给我看一下塞多谢了</td>\n",
       "      <td>多谢了</td>\n",
       "      <td>我给你信息了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qid_5049427108036202403</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>想去澳州看亲戚二个星期，怎么去，求教</td>\n",
       "      <td>想去澳州看亲戚二个星期，怎么去，求教</td>\n",
       "      <td>你看亲戚，申请的是旅游签证676！澳洲旅游签证很容易的。 \\r\\n你让亲戚将他的护照签证页和...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>qid_2831512218652800922</td>\n",
       "      <td>生活</td>\n",
       "      <td>房贷事宜我想咨询一下本人家在温州苍南钱库镇上有一套房子，市值二十</td>\n",
       "      <td>我想一下本人家在温州苍南钱库镇上有一套房子，市值二十万左右，可否到杭州银行贷款，需提供哪些证件，</td>\n",
       "      <td>你好!不可以!不是同一市的房产不可以贷款!你温州的房产,要到温州的银行申请抵押贷款!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44968</th>\n",
       "      <td>qid_674883050627329082</td>\n",
       "      <td>健康</td>\n",
       "      <td>为何会做梦?我已经有7~8年的做梦经历了,天天做梦,而我才25岁</td>\n",
       "      <td>我已经有7~8年的做梦经历了,做梦,而我才25岁.而且近几年还变本加利,还讲梦话,为什么会这...</td>\n",
       "      <td>您好！做梦是人在睡眠过程中产生的一种正常的生理和心理现象。当人在深度睡眠的时候，大脑神经细胞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>qid_9172175649428541931</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>交通事故赔偿车祸使我在急诊室里住了五天，可以要求赔偿伙食费吗？</td>\n",
       "      <td>车祸使我在室里住了五天，可以要求赔偿伙食费吗？</td>\n",
       "      <td>您好。\\r\\n\\r\\n如果有关的证据是可以的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>qid_715056891459073707</td>\n",
       "      <td>商业</td>\n",
       "      <td>市盈率的多少是什么意思?</td>\n",
       "      <td></td>\n",
       "      <td>市盈率是股价除以股票的年净利润,其实多少倍的市盈率就是每只股票多少年能收回成本!市盈率越高,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>qid_1226040859075871464</td>\n",
       "      <td>健康</td>\n",
       "      <td>孕妇如何办理产检我老婆现在怀孕四个月了，我是上海户口，我老婆是外</td>\n",
       "      <td>我老婆现在怀孕四个月了，我是上海户口，我老婆是外地户口，请问去做产检，需要些什么程序，需要哪...</td>\n",
       "      <td>我同学也是外地，嫁的上海人，她去年做产检的时候，当时是听她说回户籍所在地办啥手续，再在上海建...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44924 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           qid category                               title  \\\n",
       "0      qid_1815059893214501395       烦恼   请问深入骨髓地喜欢一个人怎么办我不能确定对方是不是喜欢我，我却想    \n",
       "1      qid_2063849676113062517       游戏  我登陆诛仙2时总说我账号密码错误，但是我打的是正确的，就算不对我?    \n",
       "2      qid_6625582808814915192       游戏                        斩魔仙者称号怎么得来的    \n",
       "3      qid_9204493405205415849       商业     有哪位好心人上传一份女衬衫的加拿大海关发票给我看一下塞多谢了    \n",
       "4      qid_5049427108036202403       娱乐                 想去澳州看亲戚二个星期，怎么去，求教    \n",
       "...                        ...      ...                                 ...   \n",
       "44967  qid_2831512218652800922       生活   房贷事宜我想咨询一下本人家在温州苍南钱库镇上有一套房子，市值二十    \n",
       "44968   qid_674883050627329082       健康   为何会做梦?我已经有7~8年的做梦经历了,天天做梦,而我才25岁    \n",
       "44969  qid_9172175649428541931       娱乐    交通事故赔偿车祸使我在急诊室里住了五天，可以要求赔偿伙食费吗？    \n",
       "44970   qid_715056891459073707       商业                       市盈率的多少是什么意思?    \n",
       "44971  qid_1226040859075871464       健康   孕妇如何办理产检我老婆现在怀孕四个月了，我是上海户口，我老婆是外    \n",
       "\n",
       "                                                    desc  \\\n",
       "0              我不能确定对方是不是喜欢我，我却想分分秒秒跟他在一起，有谁能告诉我如何能想他少一点   \n",
       "1                                                          \n",
       "2                                            斩魔仙者称号怎么得来的   \n",
       "3                                                    多谢了   \n",
       "4                                     想去澳州看亲戚二个星期，怎么去，求教   \n",
       "...                                                  ...   \n",
       "44967   我想一下本人家在温州苍南钱库镇上有一套房子，市值二十万左右，可否到杭州银行贷款，需提供哪些证件，   \n",
       "44968  我已经有7~8年的做梦经历了,做梦,而我才25岁.而且近几年还变本加利,还讲梦话,为什么会这...   \n",
       "44969                            车祸使我在室里住了五天，可以要求赔偿伙食费吗？   \n",
       "44970                                                      \n",
       "44971  我老婆现在怀孕四个月了，我是上海户口，我老婆是外地户口，请问去做产检，需要些什么程序，需要哪...   \n",
       "\n",
       "                                                  answer  \n",
       "0      一定要告诉他你很喜欢他 很爱他!!  虽然不知道你和他现在的关系是什么！但如果真的觉得很喜欢...  \n",
       "1      被盗号了~我的号在22号那天被盗了，跟你一样情况，link密码与账号错误，我密保都有了呐，邮...  \n",
       "2      楼主您好，以下为转载：\\r\\r圣诞前热身 来《生肖传说》做斩魔仙者\\r\\r　　一年一度的圣诞...  \n",
       "3                                                 我给你信息了  \n",
       "4      你看亲戚，申请的是旅游签证676！澳洲旅游签证很容易的。 \\r\\n你让亲戚将他的护照签证页和...  \n",
       "...                                                  ...  \n",
       "44967         你好!不可以!不是同一市的房产不可以贷款!你温州的房产,要到温州的银行申请抵押贷款!  \n",
       "44968  您好！做梦是人在睡眠过程中产生的一种正常的生理和心理现象。当人在深度睡眠的时候，大脑神经细胞...  \n",
       "44969                            您好。\\r\\n\\r\\n如果有关的证据是可以的。  \n",
       "44970  市盈率是股价除以股票的年净利润,其实多少倍的市盈率就是每只股票多少年能收回成本!市盈率越高,...  \n",
       "44971  我同学也是外地，嫁的上海人，她去年做产检的时候，当时是听她说回户籍所在地办啥手续，再在上海建...  \n",
       "\n",
       "[44924 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category column reserve two char\n",
    "dataset[\"category\"] = dataset[\"category\"].apply(lambda x: x[:2])\n",
    "# remove item with category is \"\"\n",
    "dataset = dataset[dataset[\"category\"] != \"\"]\n",
    "dataset[\"category\"].value_counts()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'烦恼': 0,\n",
       " '游戏': 1,\n",
       " '商业': 2,\n",
       " '娱乐': 3,\n",
       " '生活': 4,\n",
       " '教育': 5,\n",
       " '育儿': 6,\n",
       " '健康': 7,\n",
       " '文化': 8,\n",
       " '电脑': 9,\n",
       " '社会': 10,\n",
       " '电子': 11,\n",
       " '体育': 12,\n",
       " '汽车': 13,\n",
       " '资源': 14,\n",
       " '医疗': 15}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = dataset[\"category\"].unique().tolist()\n",
    "labels = {label: i for i, label in enumerate(label_list)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        super().__init__()\n",
    "        self.labels = [labels[label] for label in dataset[\"category\"]]\n",
    "        self.questions = [tokenizer(text,\n",
    "                                    padding=\"max_length\",\n",
    "                                    max_length=512,\n",
    "                                    truncation=True,\n",
    "                                    return_tensors=\"pt\")\n",
    "                          for text in dataset[\"title\"]]\n",
    "        # 不要忘记 return_tensors=\"pt\"\n",
    "    \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, index):\n",
    "        return np.array(self.labels[index])\n",
    "\n",
    "    def get_batch_questions(self, index):\n",
    "        return self.questions[index]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.get_batch_questions(index), self.get_batch_labels(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35939 4492 4493\n"
     ]
    }
   ],
   "source": [
    "# 训练集:验证集:测试集 = 8:1:1\n",
    "np.random.seed(42)\n",
    "dataset_train, dataset_validate, dataset_test = np.split(dataset.sample(frac=1, random_state=42), [int(.8*len(dataset)), int(.9*len(dataset))])\n",
    "print(len(dataset_train), len(dataset_validate), len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifer(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, len(labels))\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_id, attention_mask=mask, return_dict=False)  # 不加 return_dict=False 会报错\n",
    "        output = self.dropout(pooled_output)\n",
    "        output = self.linear(output)\n",
    "        output = self.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickletools import optimize\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get device ojbect according to the system\n",
    "def get_device() -> str:\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "def train(model: torch.nn.Module, train_data, val_data, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2, shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            mask = train_input[\"attention_mask\"].to(device)\n",
    "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        for val_input, val_label in val_dataloader:\n",
    "\n",
    "            mask = val_input['attention_mask'].to(device)\n",
    "            input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_loss_val += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "            total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "\n",
    "EPOCHS = 5\n",
    "model = BertClassifer()\n",
    "LR = 1e-6\n",
    "\n",
    "train(model, dataset_train, dataset_validate, LR, EPOCHS)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cf3a2657c4530458a1d5b90a9ba637718c74089d900d5938397f33b4197fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
